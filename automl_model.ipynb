{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1615653037752
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import csv\n",
    "import joblib\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import InferenceConfig \n",
    "from azureml.core.webservice import AciWebservice, Webservice\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1615653045025
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: final-prj\n",
      "Azure region: westus2\n",
      "Subscription id: 0c66ad45-500d-48af-80d3-0039ebf1975e\n",
      "Resource group: rgp\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws.write_config(path='.azureml')\n",
    "experiment_name = 'camels-exp'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
    "\n",
    "run = exp.start_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "The primary objective was to develop an early warning system, i.e. binary classification of failed (`'Target'==1`) vs. survived (`'Target'==0`), for the US banks using their quarterly filings with the regulator. Overall, 137 failed banks and 6,877 surviving banks were used in this machine learning exercise. Historical observations from the first 4 quarters ending 2010Q3 (stored in `./data`) are used to tune the model and out-of-sample testing is performed on quarterly data starting from 2010Q4 (stored in `./oos`).  For more information on methodology please refer to supplemental `CAMELS.md` file included in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1615653058178
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final-prj\n",
      "rgp\n",
      "westus2\n",
      "0c66ad45-500d-48af-80d3-0039ebf1975e\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1615653060569
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>camels-exp</td><td>final-prj</td><td><a href=\"https://ml.azure.com/experiments/camels-exp?wsid=/subscriptions/0c66ad45-500d-48af-80d3-0039ebf1975e/resourcegroups/rgp/workspaces/final-prj\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: camels-exp,\n",
       "Workspace: final-prj)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = 'camels-exp'\n",
    "project_folder = './dmik'\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1615653124707
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>EQTA</th>\n",
       "      <th>EQTL</th>\n",
       "      <th>LLRTA</th>\n",
       "      <th>LLRGL</th>\n",
       "      <th>OEXTA</th>\n",
       "      <th>INCEMP</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>TDTL</th>\n",
       "      <th>TDTA</th>\n",
       "      <th>TATA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7014.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "      <td>7020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.019516</td>\n",
       "      <td>0.107825</td>\n",
       "      <td>8.025950</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.021934</td>\n",
       "      <td>0.024020</td>\n",
       "      <td>33.658510</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>-0.234058</td>\n",
       "      <td>44.756417</td>\n",
       "      <td>0.835683</td>\n",
       "      <td>0.176412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.138338</td>\n",
       "      <td>0.048877</td>\n",
       "      <td>573.594468</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.160890</td>\n",
       "      <td>0.030903</td>\n",
       "      <td>1156.779875</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>11.397990</td>\n",
       "      <td>3147.677966</td>\n",
       "      <td>0.080119</td>\n",
       "      <td>0.142363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.160659</td>\n",
       "      <td>-0.195857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012004</td>\n",
       "      <td>-3639.467742</td>\n",
       "      <td>-0.295750</td>\n",
       "      <td>-887.458333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087487</td>\n",
       "      <td>0.125263</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>0.012119</td>\n",
       "      <td>0.018253</td>\n",
       "      <td>3.084559</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>1.126635</td>\n",
       "      <td>0.805493</td>\n",
       "      <td>0.066298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101018</td>\n",
       "      <td>0.156656</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.015915</td>\n",
       "      <td>0.022036</td>\n",
       "      <td>18.162698</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.045176</td>\n",
       "      <td>1.273882</td>\n",
       "      <td>0.850135</td>\n",
       "      <td>0.148018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121013</td>\n",
       "      <td>0.212105</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>34.348039</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.078245</td>\n",
       "      <td>1.527407</td>\n",
       "      <td>0.883593</td>\n",
       "      <td>0.258563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968116</td>\n",
       "      <td>47829.250000</td>\n",
       "      <td>0.161906</td>\n",
       "      <td>12.250000</td>\n",
       "      <td>2.164806</td>\n",
       "      <td>73600.000000</td>\n",
       "      <td>0.173673</td>\n",
       "      <td>21.963100</td>\n",
       "      <td>260238.500000</td>\n",
       "      <td>1.151905</td>\n",
       "      <td>0.868327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Target         EQTA          EQTL        LLRTA        LLRGL  \\\n",
       "count  7020.000000  7020.000000   7020.000000  7020.000000  7020.000000   \n",
       "mean      0.019516     0.107825      8.025950     0.012320     0.021934   \n",
       "std       0.138338     0.048877    573.594468     0.009366     0.160890   \n",
       "min       0.000000    -0.160659     -0.195857     0.000000     0.000000   \n",
       "25%       0.000000     0.087487      0.125263     0.007216     0.012119   \n",
       "50%       0.000000     0.101018      0.156656     0.010040     0.015915   \n",
       "75%       0.000000     0.121013      0.212105     0.014293     0.022124   \n",
       "max       1.000000     0.968116  47829.250000     0.161906    12.250000   \n",
       "\n",
       "             OEXTA        INCEMP          ROA          ROE           TDTL  \\\n",
       "count  7020.000000   7014.000000  7020.000000  7020.000000    7020.000000   \n",
       "mean      0.024020     33.658510     0.002020    -0.234058      44.756417   \n",
       "std       0.030903   1156.779875     0.015031    11.397990    3147.677966   \n",
       "min      -0.012004  -3639.467742    -0.295750  -887.458333       0.000000   \n",
       "25%       0.018253      3.084559     0.000907     0.009412       1.126635   \n",
       "50%       0.022036     18.162698     0.004832     0.045176       1.273882   \n",
       "75%       0.026400     34.348039     0.008417     0.078245       1.527407   \n",
       "max       2.164806  73600.000000     0.173673    21.963100  260238.500000   \n",
       "\n",
       "              TDTA         TATA  \n",
       "count  7020.000000  7020.000000  \n",
       "mean      0.835683     0.176412  \n",
       "std       0.080119     0.142363  \n",
       "min       0.000000     0.000000  \n",
       "25%       0.805493     0.066298  \n",
       "50%       0.850135     0.148018  \n",
       "75%       0.883593     0.258563  \n",
       "max       1.151905     0.868327  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ws.datasets['camels'] \n",
    "df = dataset.to_pandas_dataframe()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "gather": {
     "logged": 1615653124827
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing compute target.\n",
      "{\n",
      "  \"errors\": [],\n",
      "  \"creationTime\": \"2021-03-12T16:36:50.492879+00:00\",\n",
      "  \"createdBy\": {\n",
      "    \"userObjectId\": \"49e75006-b9ac-415c-9176-f83c59d4bf26\",\n",
      "    \"userTenantId\": \"d689239e-c492-40c6-b391-2c5951d31d14\",\n",
      "    \"userName\": \"Mikhaylov, Dmitry\"\n",
      "  },\n",
      "  \"modifiedTime\": \"2021-03-12T16:39:52.341446+00:00\",\n",
      "  \"state\": \"Running\",\n",
      "  \"vmSize\": \"STANDARD_DS3_V2\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cpu_cluster_name = 'cmp'\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Existing compute target.')\n",
    "\n",
    "except:\n",
    "    print('Creating compute target.')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "print(compute_target.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "Financial metrics recorded in the last reports of the failed banks should have predictive power that is needed to forecast future failures. Due to significant class imbalances and taking into account costs accosiated with financial distress, the model should aim to maximize the recall score. In other words, accuracy is probably not the best metrics, as Type II error needs to be minimized.\n",
    "\n",
    "The main focus of this classification should be on maximizing AUC, hopefully, by achieving good recall score. This is why `'norm_macro_recall'` was chosen as a primary metric. Timeout and number of concurrent iterations were set conservatively to control the costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "gather": {
     "logged": 1615653124941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 4,\n",
    "    \"primary_metric\" : 'norm_macro_recall'\n",
    "    }\n",
    "\n",
    "# Put your automl config here\n",
    "automl_config = AutoMLConfig(\n",
    "    compute_target=compute_target, \n",
    "    task = \"classification\",\n",
    "    training_data=dataset, \n",
    "    label_column_name=\"Target\", \n",
    "    path = project_folder,\n",
    "    enable_early_stopping= True, \n",
    "    featurization= 'auto', \n",
    "    debug_log = \"automl_errors.log\",\n",
    "    **automl_settings\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote.\n",
      "No run_configuration provided, running on cmp with default configuration\n",
      "Running on remote compute: cmp\n",
      "Parent Run ID: AutoML_1357bf3c-d371-4641-9522-bfcb8d5290a0\n",
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetBalancing. Performing class balancing sweeping\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Cross validation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
      "              \n",
      "DETAILS:      \n",
      "+---------------------------------+\n",
      "|Number of folds                  |\n",
      "+=================================+\n",
      "|3                                |\n",
      "+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Class balancing detection\n",
      "STATUS:       ALERTED\n",
      "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
      "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
      "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
      "+=================================+=================================+======================================+\n",
      "|137                              |1                                |7020                                  |\n",
      "+---------------------------------+---------------------------------+--------------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       DONE\n",
      "DESCRIPTION:  If the missing values are expected, let the run complete. Otherwise cancel the current run and use a script to customize the handling of missing feature values that may be more appropriate based on the data type and business requirement.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "DETAILS:      \n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "|Column name                      |Missing value count              |Imputation type                  |\n",
      "+=================================+=================================+=================================+\n",
      "|INCEMP                           |6                                |mean                             |\n",
      "+---------------------------------+---------------------------------+---------------------------------+\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:52       0.5628    0.5628\n",
      "         1   MaxAbsScaler XGBoostClassifier                 0:00:49       0.6775    0.6775\n",
      "         2   MinMaxScaler RandomForest                      0:00:55       0.9151    0.9151\n",
      "         3   MinMaxScaler RandomForest                      0:01:01       0.3820    0.9151\n",
      "         4   StandardScalerWrapper RandomForest             0:00:50       0.9261    0.9261\n",
      "         5   StandardScalerWrapper RandomForest             0:00:48       0.7364    0.9261\n",
      "         7   MinMaxScaler RandomForest                      0:00:42       0.0000    0.9261\n",
      "         6   MinMaxScaler ExtremeRandomTrees                0:00:53       0.6125    0.9261\n",
      "         8   MinMaxScaler ExtremeRandomTrees                0:00:48       0.0000    0.9261\n",
      "         9   RobustScaler ExtremeRandomTrees                0:00:59       0.0000    0.9261\n",
      "        10   MinMaxScaler ExtremeRandomTrees                0:01:25       0.0000    0.9261\n",
      "        11   RobustScaler ExtremeRandomTrees                0:01:15       0.0000    0.9261\n",
      "        12   StandardScalerWrapper ExtremeRandomTrees       0:00:49       0.8432    0.9261\n",
      "        13   StandardScalerWrapper SGD                      0:00:50       0.4586    0.9261\n"
     ]
    }
   ],
   "source": [
    "# Submit your automl run\n",
    "remote_run = experiment.submit(config=automl_config, show_output=True)\n",
    "RunDetails(remote_run).show()\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1615659118400
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Status:  Completed\n"
     ]
    }
   ],
   "source": [
    "# Fetch the latest status of the run. It should show 'Completed'\n",
    "print(\"Run Status: \",remote_run.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1615659141873
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-automl-runtime, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-core, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-dataprep, training version:2.10.1, current version:2.9.1\n",
      "Package:azureml-dataprep-native, training version:30.0.0, current version:29.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.8.0, current version:1.7.0\n",
      "Package:azureml-dataset-runtime, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-defaults, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-interpret, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-mlflow, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-pipeline-core, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-telemetry, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-train-automl-client, training version:1.23.0, current version:1.22.0\n",
      "Package:azureml-train-automl-runtime, training version:1.23.0, current version:1.22.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run: Run(Experiment: camels-exp,\n",
      "Id: AutoML_1357bf3c-d371-4641-9522-bfcb8d5290a0_36,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "Best model: Pipeline(memory=None,\n",
      "         steps=[('datatransformer',\n",
      "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
      "                                 feature_sweeping_config=None,\n",
      "                                 feature_sweeping_timeout=None,\n",
      "                                 featurization_config=None, force_text_dnn=None,\n",
      "                                 is_cross_validation=None,\n",
      "                                 is_onnx_compatible=None, logger=None,\n",
      "                                 observer=None, task=None, working_dir=None)),\n",
      "                ('prefittedsoftvotingclassifier',...\n",
      "                                                                                                  min_samples_leaf=0.035789473684210524,\n",
      "                                                                                                  min_samples_split=0.15052631578947367,\n",
      "                                                                                                  min_weight_fraction_leaf=0.0,\n",
      "                                                                                                  n_estimators=25,\n",
      "                                                                                                  n_jobs=1,\n",
      "                                                                                                  oob_score=True,\n",
      "                                                                                                  random_state=None,\n",
      "                                                                                                  verbose=0,\n",
      "                                                                                                  warm_start=False))],\n",
      "                                                                     verbose=False))],\n",
      "                                               flatten_transform=None,\n",
      "                                               weights=[0.16666666666666666,\n",
      "                                                        0.16666666666666666,\n",
      "                                                        0.16666666666666666,\n",
      "                                                        0.16666666666666666,\n",
      "                                                        0.16666666666666666,\n",
      "                                                        0.16666666666666666]))],\n",
      "         verbose=False)\n",
      "precision_score_macro 0.6727537257984412\n",
      "precision_score_micro 0.9632478632478633\n",
      "accuracy 0.9632478632478633\n",
      "balanced_accuracy 0.9734297779053027\n",
      "norm_macro_recall 0.9468595558106054\n",
      "f1_score_weighted 0.9718584632028456\n",
      "f1_score_macro 0.745334132126911\n",
      "f1_score_micro 0.9632478632478633\n",
      "matthews_correlation 0.5705694287251595\n",
      "recall_score_macro 0.9734297779053027\n",
      "weighted_accuracy 0.9628224215229398\n",
      "average_precision_score_weighted 0.9926640960445484\n",
      "recall_score_weighted 0.9632478632478633\n",
      "average_precision_score_macro 0.8197719095107118\n",
      "precision_score_weighted 0.9870706121607657\n",
      "average_precision_score_micro 0.9897003398796621\n",
      "recall_score_micro 0.9632478632478633\n",
      "AUC_micro 0.9894314169527845\n",
      "AUC_weighted 0.9817345418070547\n",
      "log_loss 0.16563326577338694\n",
      "AUC_macro 0.9817345418070547\n",
      "accuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_1357bf3c-d371-4641-9522-bfcb8d5290a0_36/accuracy_table\n",
      "confusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_1357bf3c-d371-4641-9522-bfcb8d5290a0_36/confusion_matrix\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and save your best automl model.\n",
    "best_run, fitted_model = remote_run.get_output()\n",
    "\n",
    "print('Best run:', best_run)\n",
    "print('Best model:', fitted_model)\n",
    "\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "\n",
    "for metric_name in best_run_metrics:\n",
    "    metric = best_run_metrics[metric_name]\n",
    "    print(metric_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "gather": {
     "logged": 1615659417097
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fitted_automl_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the best model\n",
    "joblib.dump(value=fitted_model, filename=\"fitted_automl_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "gather": {
     "logged": 1615660740829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Register the model produced by AutoML\n",
    "automl_model = remote_run.register_model(model_name='automl_model.pkl') #, model_path = './outputs/')\n",
    "\n",
    "#model = remote_run.register_model(model_name = 'house_price_model.pkl')\n",
    "print(remote_run.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "gather": {
     "logged": 1615661075365
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running...............................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "environment = best_run.get_environment()\n",
    "entry_script='inference/scoring.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', entry_script)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script = entry_script, environment = environment)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                                    memory_gb = 1, \n",
    "                                                    auth_enabled= True, \n",
    "                                                    enable_app_insights= True)\n",
    "\n",
    "service = Model.deploy(ws, \"aciservice\", [automl_model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "gather": {
     "logged": 1615661681350
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service state: Healthy\n",
      "Service scoring URI: http://9a8e86e1-3449-480d-bb35-a6cd6731753a.westus2.azurecontainer.io/score\n",
      "Service Swagger URI: http://9a8e86e1-3449-480d-bb35-a6cd6731753a.westus2.azurecontainer.io/swagger.json\n",
      "Service primary authentication key: KdVguq2bEEr4ug7K20EesDrdmpZkLYY2\n"
     ]
    }
   ],
   "source": [
    "# If authentication is enabled, so I use the get_keys method to retrieve the primary and secondary authentication keys:\n",
    "primary, secondary = service.get_keys()\n",
    "\n",
    "print('Service state: ' + service.state)\n",
    "print('Service scoring URI: ' + service.scoring_uri)\n",
    "print('Service Swagger URI: ' + service.swagger_uri)\n",
    "print('Service primary authentication key: ' + primary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "Print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "gather": {
     "logged": 1615661690265
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-13T18:44:14,032572600+00:00 - gunicorn/run \n",
      "2021-03-13T18:44:14,034772100+00:00 - rsyslog/run \n",
      "2021-03-13T18:44:14,041727100+00:00 - iot-server/run \n",
      "2021-03-13T18:44:14,069706800+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "rsyslogd: /azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-03-13T18:44:15,930353400+00:00 - iot-server/finish 1 0\n",
      "2021-03-13T18:44:15,946744300+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (65)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 97\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Generating new fontManager, this may take some time...\n",
      "Initializing logger\n",
      "2021-03-13 18:44:20,843 | root | INFO | Starting up app insights client\n",
      "2021-03-13 18:44:20,844 | root | INFO | Starting up request id generator\n",
      "2021-03-13 18:44:20,844 | root | INFO | Starting up app insight hooks\n",
      "2021-03-13 18:44:20,845 | root | INFO | Invoking user's init function\n",
      "2021-03-13 18:44:31,292 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (cryptography 3.2 (/azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/python3.6/site-packages), Requirement.parse('cryptography<4.0.0,>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (cryptography 3.2 (/azureml-envs/azureml_661474bbe74e96b5d8added5888dfc85/lib/python3.6/site-packages), Requirement.parse('cryptography<4.0.0,>=3.3.1; extra == \"crypto\"'), {'PyJWT'}).\n",
      "2021-03-13 18:44:31,725 | root | INFO | Users's init has completed successfully\n",
      "2021-03-13 18:44:31,732 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-03-13 18:44:31,732 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-03-13 18:44:31,735 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-03-13 18:44:31,749 | root | INFO | 200\n",
      "127.0.0.1 - - [13/Mar/2021:18:44:31 +0000] \"GET /swagger.json HTTP/1.0\" 200 2692 \"-\" \"Go-http-client/1.1\"\n",
      "2021-03-13 18:44:35,754 | root | INFO | 200\n",
      "127.0.0.1 - - [13/Mar/2021:18:44:35 +0000] \"GET /swagger.json HTTP/1.0\" 200 2692 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the logs\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Delete the cluster instance\n",
    "#AmlCompute.delete(compute_target)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
