{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1615569207325
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ws.write_config(path='.azureml')\n",
        "experiment_name = 'camels-exp'\n",
        "exp = Experiment(workspace=ws, name=experiment_name)\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing interactive authentication. Please follow the instructions on the terminal.\n",
            "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code AUCVNXZZL to authenticate.\n",
            "You have logged in. Now let us find all the subscriptions to which you have access...\n",
            "Interactive authentication successfully completed.\n",
            "Workspace name: final-prj\n",
            "Azure region: westus2\n",
            "Subscription id: 0c66ad45-500d-48af-80d3-0039ebf1975e\n",
            "Resource group: rgp\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615569083660
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# my code\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final-prj\n",
            "rgp\n",
            "westus2\n",
            "0c66ad45-500d-48af-80d3-0039ebf1975e\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615569106176
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# my code\n",
        "experiment_name = 'camels-exp'\n",
        "project_folder = './dmik'\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "Experiment(Name: camels-exp,\nWorkspace: final-prj)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>camels-exp</td><td>final-prj</td><td><a href=\"https://ml.azure.com/experiments/camels-exp?wsid=/subscriptions/0c66ad45-500d-48af-80d3-0039ebf1975e/resourcegroups/rgp/workspaces/final-prj\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615569113530
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# my code\n",
        "dataset = ws.datasets['camels'] \n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "            Target         EQTA          EQTL        LLRTA        LLRGL  \\\ncount  7020.000000  7020.000000   7020.000000  7020.000000  7020.000000   \nmean      0.019516     0.107825      8.025950     0.012320     0.021934   \nstd       0.138338     0.048877    573.594468     0.009366     0.160890   \nmin       0.000000    -0.160659     -0.195857     0.000000     0.000000   \n25%       0.000000     0.087487      0.125263     0.007216     0.012119   \n50%       0.000000     0.101018      0.156656     0.010040     0.015915   \n75%       0.000000     0.121013      0.212105     0.014293     0.022124   \nmax       1.000000     0.968116  47829.250000     0.161906    12.250000   \n\n             OEXTA        INCEMP          ROA          ROE           TDTL  \\\ncount  7020.000000   7014.000000  7020.000000  7020.000000    7020.000000   \nmean      0.024020     33.658510     0.002020    -0.234058      44.756417   \nstd       0.030903   1156.779875     0.015031    11.397990    3147.677966   \nmin      -0.012004  -3639.467742    -0.295750  -887.458333       0.000000   \n25%       0.018253      3.084559     0.000907     0.009412       1.126635   \n50%       0.022036     18.162698     0.004832     0.045176       1.273882   \n75%       0.026400     34.348039     0.008417     0.078245       1.527407   \nmax       2.164806  73600.000000     0.173673    21.963100  260238.500000   \n\n              TDTA         TATA  \ncount  7020.000000  7020.000000  \nmean      0.835683     0.176412  \nstd       0.080119     0.142363  \nmin       0.000000     0.000000  \n25%       0.805493     0.066298  \n50%       0.850135     0.148018  \n75%       0.883593     0.258563  \nmax       1.151905     0.868327  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Target</th>\n      <th>EQTA</th>\n      <th>EQTL</th>\n      <th>LLRTA</th>\n      <th>LLRGL</th>\n      <th>OEXTA</th>\n      <th>INCEMP</th>\n      <th>ROA</th>\n      <th>ROE</th>\n      <th>TDTL</th>\n      <th>TDTA</th>\n      <th>TATA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7014.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n      <td>7020.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.019516</td>\n      <td>0.107825</td>\n      <td>8.025950</td>\n      <td>0.012320</td>\n      <td>0.021934</td>\n      <td>0.024020</td>\n      <td>33.658510</td>\n      <td>0.002020</td>\n      <td>-0.234058</td>\n      <td>44.756417</td>\n      <td>0.835683</td>\n      <td>0.176412</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.138338</td>\n      <td>0.048877</td>\n      <td>573.594468</td>\n      <td>0.009366</td>\n      <td>0.160890</td>\n      <td>0.030903</td>\n      <td>1156.779875</td>\n      <td>0.015031</td>\n      <td>11.397990</td>\n      <td>3147.677966</td>\n      <td>0.080119</td>\n      <td>0.142363</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-0.160659</td>\n      <td>-0.195857</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.012004</td>\n      <td>-3639.467742</td>\n      <td>-0.295750</td>\n      <td>-887.458333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>0.087487</td>\n      <td>0.125263</td>\n      <td>0.007216</td>\n      <td>0.012119</td>\n      <td>0.018253</td>\n      <td>3.084559</td>\n      <td>0.000907</td>\n      <td>0.009412</td>\n      <td>1.126635</td>\n      <td>0.805493</td>\n      <td>0.066298</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>0.101018</td>\n      <td>0.156656</td>\n      <td>0.010040</td>\n      <td>0.015915</td>\n      <td>0.022036</td>\n      <td>18.162698</td>\n      <td>0.004832</td>\n      <td>0.045176</td>\n      <td>1.273882</td>\n      <td>0.850135</td>\n      <td>0.148018</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.000000</td>\n      <td>0.121013</td>\n      <td>0.212105</td>\n      <td>0.014293</td>\n      <td>0.022124</td>\n      <td>0.026400</td>\n      <td>34.348039</td>\n      <td>0.008417</td>\n      <td>0.078245</td>\n      <td>1.527407</td>\n      <td>0.883593</td>\n      <td>0.258563</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>0.968116</td>\n      <td>47829.250000</td>\n      <td>0.161906</td>\n      <td>12.250000</td>\n      <td>2.164806</td>\n      <td>73600.000000</td>\n      <td>0.173673</td>\n      <td>21.963100</td>\n      <td>260238.500000</td>\n      <td>1.151905</td>\n      <td>0.868327</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615569135684
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cpu_cluster_name = 'cmp'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Existing compute target.')\n",
        "\n",
        "except:\n",
        "    print('Creating compute target.')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "\n",
        "print(compute_target.get_status())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Existing compute target.\n",
            "{\n",
            "  \"errors\": [],\n",
            "  \"creationTime\": \"2021-03-12T16:36:50.492879+00:00\",\n",
            "  \"createdBy\": {\n",
            "    \"userObjectId\": \"49e75006-b9ac-415c-9176-f83c59d4bf26\",\n",
            "    \"userTenantId\": \"d689239e-c492-40c6-b391-2c5951d31d14\",\n",
            "    \"userName\": \"Mikhaylov, Dmitry\"\n",
            "  },\n",
            "  \"modifiedTime\": \"2021-03-12T16:39:52.341446+00:00\",\n",
            "  \"state\": \"Running\",\n",
            "  \"vmSize\": \"STANDARD_DS3_V2\"\n",
            "}\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615569600480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598423890461
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20,\n",
        "    \"max_concurrent_iterations\": 5,\n",
        "    \"primary_metric\" : 'norm_macro_recall'\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "\n",
        "\n",
        "automl_config = AutoMLConfig(compute_target=compute_target,\n",
        "                             task = \"classification\",\n",
        "                             training_data=dataset,\n",
        "                             label_column_name=\"Target\",   \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True,\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1615569624131
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(automl_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on remote.\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1615569634971
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "from azureml.widgets import RunDetails\n",
        "run = experiment.submit(config=automl_config, show_output=True)\n",
        "RunDetails(run).show()\n",
        "run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on remote.\n",
            "Running on remote compute: cmp\n",
            "Parent Run ID: AutoML_490852a9-29a8-4669-9062-51eb24f6b59c\n",
            "\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: DatasetBalancing. Performing class balancing sweeping\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Cross validation\n",
            "STATUS:       DONE\n",
            "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
            "              \n",
            "DETAILS:      \n",
            "+---------------------------------+\n",
            "|Number of folds                  |\n",
            "+=================================+\n",
            "|3                                |\n",
            "+---------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       ALERTED\n",
            "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
            "+=================================+=================================+======================================+\n",
            "|137                              |1                                |7020                                  |\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       DONE\n",
            "DESCRIPTION:  If the missing values are expected, let the run complete. Otherwise cancel the current run and use a script to customize the handling of missing feature values that may be more appropriate based on the data type and business requirement.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "DETAILS:      \n",
            "+---------------------------------+---------------------------------+---------------------------------+\n",
            "|Column name                      |Missing value count              |Imputation type                  |\n",
            "+=================================+=================================+=================================+\n",
            "|INCEMP                           |6                                |mean                             |\n",
            "+---------------------------------+---------------------------------+---------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:00:55       0.5628    0.5628\n",
            "         1   MaxAbsScaler XGBoostClassifier                 0:00:52       0.6775    0.6775\n",
            "         2   MinMaxScaler RandomForest                      0:00:55       0.9223    0.9223\n",
            "         4   StandardScalerWrapper RandomForest             0:00:55       0.9177    0.9223\n",
            "         3   MinMaxScaler RandomForest                      0:00:57       0.4194    0.9223\n",
            "         5   StandardScalerWrapper RandomForest             0:00:58       0.7033    0.9223\n",
            "         6   MinMaxScaler ExtremeRandomTrees                0:00:59       0.8855    0.9223\n",
            "         8   MinMaxScaler ExtremeRandomTrees                0:00:55       0.0000    0.9223\n",
            "         9   RobustScaler ExtremeRandomTrees                0:00:59       0.0000    0.9223\n",
            "         7   MinMaxScaler RandomForest                      0:01:00       0.0000    0.9223\n",
            "        10   MinMaxScaler ExtremeRandomTrees                0:00:56       0.0000    0.9223\n",
            "        14   RobustScaler RandomForest                      0:00:50       0.9336    0.9336\n",
            "        11   RobustScaler ExtremeRandomTrees                0:00:59       0.0000    0.9336\n",
            "        12   StandardScalerWrapper ExtremeRandomTrees       0:00:58       0.8164    0.9336\n",
            "        13   StandardScalerWrapper SGD                      0:00:49       0.4365    0.9336\n",
            "        15   MinMaxScaler ExtremeRandomTrees                0:00:51       0.0000    0.9336\n",
            "        17   RobustScaler ExtremeRandomTrees                0:00:51       0.0000    0.9336\n",
            "        18   RobustScaler RandomForest                      0:00:50       0.9210    0.9336\n",
            "        19   MinMaxScaler ExtremeRandomTrees                0:00:50       0.8226    0.9336\n",
            "        16   StandardScalerWrapper RandomForest             0:01:05       0.9386    0.9386\n",
            "        20   MaxAbsScaler ExtremeRandomTrees                0:00:52       0.8646    0.9386\n",
            "        21   StandardScalerWrapper XGBoostClassifier        0:00:49       0.6868    0.9386\n",
            "        22   MaxAbsScaler RandomForest                      0:00:50       0.5082    0.9386\n",
            "        23   MaxAbsScaler ExtremeRandomTrees                0:00:50       0.6867    0.9386\n",
            "        24   StandardScalerWrapper ExtremeRandomTrees       0:00:57       0.8918    0.9386\n",
            "        25   MaxAbsScaler RandomForest                      0:00:53       0.0000    0.9386\n",
            "        26   StandardScalerWrapper XGBoostClassifier        0:01:15       0.6364    0.9386\n",
            "        27   MinMaxScaler GradientBoosting                  0:01:04       0.6886    0.9386\n",
            "        28   StandardScalerWrapper XGBoostClassifier        0:01:09       0.6359    0.9386\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1598431121770
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "best_run, fitted_model = run.get_output()\n",
        "print(fitted_model)\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "for metric_name in best_run_metrics:\n",
        "    metric = best_run_metrics[metric_name]\n",
        "    print(metric_name, metric)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
            "WARNING:root:The consistency in the result may not be guaranteed.\n",
            "WARNING:root:Package:azureml-automl-core, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-automl-runtime, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-core, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-dataprep, training version:2.10.1, current version:2.9.1\n",
            "Package:azureml-dataprep-native, training version:30.0.0, current version:29.0.0\n",
            "Package:azureml-dataprep-rslex, training version:1.8.0, current version:1.7.0\n",
            "Package:azureml-dataset-runtime, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-defaults, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-interpret, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-mlflow, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-pipeline-core, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-telemetry, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-train-automl-client, training version:1.23.0, current version:1.22.0\n",
            "Package:azureml-train-automl-runtime, training version:1.23.0, current version:1.22.0\n",
            "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(memory=None,\n",
            "         steps=[('datatransformer',\n",
            "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
            "                                 feature_sweeping_config=None,\n",
            "                                 feature_sweeping_timeout=None,\n",
            "                                 featurization_config=None, force_text_dnn=None,\n",
            "                                 is_cross_validation=None,\n",
            "                                 is_onnx_compatible=None, logger=None,\n",
            "                                 observer=None, task=None, working_dir=None)),\n",
            "                ('prefittedsoftvotingclassifier',...\n",
            "                                                                                                    min_impurity_split=None,\n",
            "                                                                                                    min_samples_leaf=0.01,\n",
            "                                                                                                    min_samples_split=0.29105263157894734,\n",
            "                                                                                                    min_weight_fraction_leaf=0.0,\n",
            "                                                                                                    n_estimators=25,\n",
            "                                                                                                    n_jobs=1,\n",
            "                                                                                                    oob_score=False,\n",
            "                                                                                                    random_state=None,\n",
            "                                                                                                    verbose=0,\n",
            "                                                                                                    warm_start=False))],\n",
            "                                                                     verbose=False))],\n",
            "                                               flatten_transform=None,\n",
            "                                               weights=[0.3333333333333333,\n",
            "                                                        0.16666666666666666,\n",
            "                                                        0.16666666666666666,\n",
            "                                                        0.16666666666666666,\n",
            "                                                        0.16666666666666666]))],\n",
            "         verbose=False)\n",
            "precision_score_micro 0.9669515669515669\n",
            "recall_score_micro 0.9669515669515669\n",
            "recall_score_macro 0.972188890375148\n",
            "AUC_micro 0.9897461465410182\n",
            "f1_score_micro 0.9669515669515669\n",
            "recall_score_weighted 0.9669515669515669\n",
            "average_precision_score_macro 0.8016703490937532\n",
            "precision_score_macro 0.6853210706815757\n",
            "AUC_macro 0.9818937031906098\n",
            "AUC_weighted 0.98189370319061\n",
            "average_precision_score_micro 0.9899528851095694\n",
            "precision_score_weighted 0.9874553026074445\n",
            "accuracy 0.9669515669515669\n",
            "f1_score_weighted 0.9743042279138416\n",
            "weighted_accuracy 0.9667457918709047\n",
            "balanced_accuracy 0.972188890375148\n",
            "matthews_correlation 0.5895815729703563\n",
            "average_precision_score_weighted 0.9918156099584495\n",
            "log_loss 0.124494118491024\n",
            "f1_score_macro 0.7588987483865289\n",
            "norm_macro_recall 0.9443777807502962\n",
            "accuracy_table aml://artifactId/ExperimentRun/dcid.AutoML_490852a9-29a8-4669-9062-51eb24f6b59c_39/accuracy_table\n",
            "confusion_matrix aml://artifactId/ExperimentRun/dcid.AutoML_490852a9-29a8-4669-9062-51eb24f6b59c_39/confusion_matrix\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1615572320450
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_run)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run(Experiment: camels-exp,\n",
            "Id: AutoML_490852a9-29a8-4669-9062-51eb24f6b59c_39,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed)\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1615572325837
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\n",
        "# Register the model produced by AutoML\n",
        "import joblib\n",
        "\n",
        "joblib.dump(value=fitted_model, filename=\"fitted_automl_model.joblib\")\n",
        "automl_model = best_run.register_model(model_name='automl_model.pkl', model_path = './outputs/')"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1615572343372
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598432707604
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the cluster instance\n",
        "AmlCompute.delete(compute_target)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}